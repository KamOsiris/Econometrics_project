{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Econometrics Project\n",
    "\n",
    "Enguerrand Beitz - YETNA Kam Osiris "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1 - CROSS-SECTION DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) State the fundamental hypothesis under which the Ordinary Least Squares (OLS) estimators are unbiased. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let Y = $\\beta_0$ +  $\\beta_{1} * X$ + u $\\newline$\n",
    "with : $\\newline$\n",
    "Y, the dependant variable $\\newline$\n",
    "X, the independant variable $\\newline$\n",
    "u, the error $\\newline$\n",
    "\n",
    "The fundamental hypothesis under which OLS estimators are unbiased is : $\\boxed{\\mathbb{E}(u|X) = 0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Show that under this assumption the OLS estimators are indeed unbiased. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class we saw that, the OLS for $\\beta_{1}$ and $\\beta_0$\n",
    "$$\n",
    "\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^n (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum_{i=1}^n (X_i - \\bar{X})^2} \\quad \\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1 \\bar{X}\n",
    "$$\n",
    "\n",
    "Let's start by $\\hat{\\beta}_1$:\n",
    "$$\n",
    "\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^n (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum_{i=1}^n (X_i - \\bar{X})^2} = \\frac{\\sum_{i=1}^n (X_i - \\bar{X})(\\beta_{0} + \\beta_{1}*X_{i} + u_{i} - \\bar{Y})}{\\sum_{i=1}^n (X_i - \\bar{X})^2}\n",
    "$$\n",
    "$$\n",
    "= \\frac{\\sum_{i=1}^n (X_i - \\bar{X})(\\beta_{1}*X_{i} + u_{i}) + (\\beta_{0} - \\bar{Y})(\\sum_{i=1}^n (X_i - \\bar{X}))}{\\sum_{i=1}^n (X_i - \\bar{X})^2}\n",
    "$$\n",
    "\n",
    "But\n",
    "$$\n",
    "\\boxed{\\sum_{i=1}^n (X_i - \\bar{X}) = 0}\n",
    "$$\n",
    "And\n",
    "$$\n",
    "\\bar{X}\\sum_{i=1}^n (X_i - \\bar{X}) = 0 \\Rightarrow \\boxed{\\sum_{i=1}^n \\beta_{1}*X_{i}(X_i - \\bar{X}) = \\sum_{i=1}^n \\beta_{1}*(X_{i}-\\bar{X})(X_i - \\bar{X})}\n",
    "$$\n",
    "\n",
    "So,\n",
    "$$\n",
    "\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^n \\hat{\\beta}_1(X_i - \\bar{X})^2 + (X_i - \\bar{X})u_{i}}{\\sum_{i=1}^n (X_i - \\bar{X})^2}\n",
    "$$\n",
    "So,\n",
    "$$\n",
    "\\boxed{\\hat\\beta_1 = \\beta_1 + \\frac{\\sum_{i=1}^n (X_i - \\bar{X})u_{i}}{\\sum_{i=1}^n (X_i - \\bar{X})^2}}\n",
    "$$\n",
    "But,The expected values are conditional on the sample values of the in- dependent variable. Because $\\sum_{i=1}^n (X_i - \\bar{X})^2$ and $\\sum_{i=1}^n (X_ - \\bar{X})$  are functions only of the xi, they are nonrandom in the conditioning. Therefore, and keeping the conditioning on {x1, x2, ..., xn} implicit, we have\n",
    "$$\n",
    "\\mathbb{E}(\\frac{\\sum_{i=1}^n (X_i - \\bar{X})u_{i}}{\\sum_{i=1}^n (X_i - \\bar{X})^2}) = \\frac{\\sum_{i=1}^n (X_i - \\bar{X})\\mathbb{E}(u_{i})}{\\sum_{i=1}^n (X_i - \\bar{X})^2}\n",
    "$$\n",
    "\n",
    "The fundamentale hypothesis tells us that $\\mathbb{E}(u_{i}|X_{i})= 0$. Therefore,  $\\mathbb{E}(u_{i})= 0$\n",
    "\n",
    "Thus,\n",
    "$$\n",
    "\\boxed{\\mathbb{\\hat\\beta_1} = \\beta_1 \\Rightarrow  \\text{$\\hat\\beta_1$ is unbiased}}\n",
    "$$\n",
    "\n",
    "Now, let's move on to $\\hat{\\beta}_0$:\n",
    "\n",
    "To demonstrate that $\\hat{\\beta}_0$ (the estimator of $\\beta_0$) is unbiased in the context of linear regression, we will show that the expectation of $\\hat{\\beta}_0$ is equal to $\\beta_0$.\n",
    "\n",
    "The estimator for $\\beta_0$ is defined as follows:\n",
    "$$\n",
    "\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1 \\bar{X}\n",
    "$$\n",
    "\n",
    "Now, let's calculate the expectation of $\\hat{\\beta}_0$:\n",
    "$$\n",
    "E(\\hat{\\beta}_0) = E(\\bar{Y} - \\hat{\\beta}_1 \\bar{X}) = E(\\bar{Y}) - E(\\hat{\\beta}_1 \\bar{X})\n",
    "$$\n",
    "\n",
    "Since $\\bar{Y}$ and $\\bar{X}$ are constants (non-random), we can pull them out of the expectation:\n",
    "$$\n",
    "E(\\hat{\\beta}_0) = \\bar{Y} - \\bar{X}E(\\hat{\\beta}_1)\n",
    "$$\n",
    "\n",
    "Now, the estimator for $\\beta_1$ ($\\hat{\\beta}_1$) is generally considered unbiased, so $E(\\hat{\\beta}_1) = \\beta_1$. Substituting this into the expression:\n",
    "$$\n",
    "E(\\hat{\\beta}_0) = \\bar{Y} - \\bar{X}\\beta_1\n",
    "$$\n",
    "\n",
    "Let's compare this with the true value of $\\beta_0$ in the regression model:\n",
    "$$\n",
    "\\beta_0 = E(Y) - \\beta_1E(X)\n",
    "$$\n",
    "\n",
    "Knowing that $\\bar{Y} = E(Y)$ and $\\bar{X} = E(X)$, we can rewrite the expression for $\\beta_0$:\n",
    "$$\n",
    "\\beta_0 = \\bar{Y} - \\beta_1 \\bar{X}\n",
    "$$\n",
    "\n",
    "Now, let's compare $E(\\hat{\\beta}_0)$ and $\\beta_0$:\n",
    "$$\n",
    "E(\\hat{\\beta}_0) = \\bar{Y} - \\bar{X}\\beta_1 \\Rightarrow \\boxed{\\beta_0 = \\bar{Y} - \\beta_1 \\bar{X}}\n",
    "$$\n",
    "\n",
    "As we can see, $E(\\hat{\\beta}_0) = \\beta_0$, indicating that $\\hat{\\beta}_0$ is unbiased.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Explain the sample selection bias with an example from the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample selection bias occurs when used for a study is not representative of the population we want to study. There is a distortion between the composition of the sample and the real population, which can lead to biased conclusions. \n",
    "\n",
    "Here is an example of a specific sample selection bias, which is the survival bias: this occurs when the sample is composed solely of those who survived a certain event or period. This can lead to an under-representation of individuals who did not survive, which distorts the results.\n",
    "\n",
    "Example: Assume a study which examines the relationship between the growth rate and size of companies. The Gibrat law argues that if growth is independent of size, the distribution of observed company sizes should align with the general distribution. However, early empirical studies indicate a negative relationship between growth and company size, possibly due to only the small, highly dynamic companies surviving in the market. This introduces a survival bias, as the sample includes only those companies that have survived, neglecting those that exited the market, potentially leading to inaccurate conclusions about the relationship between growth and size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Explain the omitted variable bias with an example from the course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Omitted variable bias occurs when a relevant variable that influences both the variable we are trying to predict, and the variable used to predict it is not included in the model. \n",
    "\n",
    "Example: Assume that the objective is to investigate the impact of fertilizers on soybean agricultural yields. However, that yield depends on a great number of other factors, such as climate, soil quality, presence of pests, etc. When selecting plots of land for the experiment, not all these other factors are considered in the analysis. If fertilizers are systematically applied to the better plots, it can lead to an overestimation of the impact of fertilizers on yield, as the better plots may naturally produce higher yields independently of the fertilizer effect.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Explain the problem of multicollinearity. Is it a problem in this dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem of multicollinearity arises when we want to calculate variances or standard deviations. Indeed, we have : \n",
    "\n",
    "$Var(b | X) = Var((X'X)^{-1} X'(X \\beta + u)|X)$\n",
    "\n",
    "$Var(b | X) = 0 + (X'X)^{-1} X' Var(u|X) X(X'X)^{-1}$\n",
    "\n",
    "$Var(b | X) = \\sigma ^{2}(X'X)^{-1}$\n",
    "\n",
    "The problem of multicollinearity arises when X'X is close to 0.\n",
    "\n",
    "This problem occurs when two or more columns of X are (quasi) linearly dependent.\n",
    "\n",
    "Thus, $det(X'X) = 0$ (or close)\n",
    "\n",
    "So it's difficult to calculate the inverse of X'X.\n",
    "\n",
    "In the dataset on which we are working, there is a problem of multicollinearity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Create three categories of nox levels (low, medium, high), corresponding to the following\n",
    "percentiles: 0-25%, 26%-74%, 75%-100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nox nox_category\n",
      "0  5.38       medium\n",
      "1  4.69       medium\n",
      "2  4.69       medium\n",
      "3  4.58       medium\n",
      "4  4.58       medium\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('HPRICE2.raw', sep='\\s+', header=None)\n",
    "df.columns = ['price', 'crime', 'nox', 'rooms', 'dist', 'radial', 'proptax', 'stratio', 'lowstat', 'lprice', 'lnox', 'lproptax']\n",
    "\n",
    "percentiles = df['nox'].quantile([0, 0.25, 0.75, 1.0])\n",
    "\n",
    "df['nox_category'] = pd.cut(df['nox'], bins=percentiles, labels=['low', 'medium', 'high'])\n",
    "\n",
    "print(df[['nox', 'nox_category']].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
