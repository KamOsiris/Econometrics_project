{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Econometrics Project\n",
    "\n",
    "Enguerrand Beitz - YETNA Kam Osiris "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1 - CROSS-SECTION DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) State the fundamental hypothesis under which the Ordinary Least Squares (OLS) estimators are unbiased. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let Y = $\\beta_0$ +  $\\beta_{1} * X$ + u $\\newline$\n",
    "with : $\\newline$\n",
    "Y, the dependant variable $\\newline$\n",
    "X, the independant variable $\\newline$\n",
    "u, the error $\\newline$\n",
    "\n",
    "The fundamental hypothesis under which OLS estimators are unbiased is : $\\boxed{\\mathbb{E}(u|X) = 0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Show that under this assumption the OLS estimators are indeed unbiased. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class we saw that, the OLS for $\\beta_{1}$ and $\\beta_0$\n",
    "$$\n",
    "\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^n (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum_{i=1}^n (X_i - \\bar{X})^2} \\quad \\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1 \\bar{X}\n",
    "$$\n",
    "\n",
    "Let's start by $\\hat{\\beta}_1$:\n",
    "$$\n",
    "\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^n (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum_{i=1}^n (X_i - \\bar{X})^2} = \\frac{\\sum_{i=1}^n (X_i - \\bar{X})(\\beta_{0} + \\beta_{1}*X_{i} + u_{i} - \\bar{Y})}{\\sum_{i=1}^n (X_i - \\bar{X})^2}\n",
    "$$\n",
    "$$\n",
    "= \\frac{\\sum_{i=1}^n (X_i - \\bar{X})(\\beta_{1}*X_{i} + u_{i}) + (\\beta_{0} - \\bar{Y})(\\sum_{i=1}^n (X_i - \\bar{X}))}{\\sum_{i=1}^n (X_i - \\bar{X})^2}\n",
    "$$\n",
    "\n",
    "But\n",
    "$$\n",
    "\\boxed{\\sum_{i=1}^n (X_i - \\bar{X}) = 0}\n",
    "$$\n",
    "And\n",
    "$$\n",
    "\\bar{X}\\sum_{i=1}^n (X_i - \\bar{X}) = 0 \\Rightarrow \\boxed{\\sum_{i=1}^n \\beta_{1}*X_{i}(X_i - \\bar{X}) = \\sum_{i=1}^n \\beta_{1}*(X_{i}-\\bar{X})(X_i - \\bar{X})}\n",
    "$$\n",
    "\n",
    "So,\n",
    "$$\n",
    "\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^n \\hat{\\beta}_1(X_i - \\bar{X})^2 + (X_i - \\bar{X})u_{i}}{\\sum_{i=1}^n (X_i - \\bar{X})^2}\n",
    "$$\n",
    "So,\n",
    "$$\n",
    "\\boxed{\\hat\\beta_1 = \\beta_1 + \\frac{\\sum_{i=1}^n (X_i - \\bar{X})u_{i}}{\\sum_{i=1}^n (X_i - \\bar{X})^2}}\n",
    "$$\n",
    "But,The expected values are conditional on the sample values of the in- dependent variable. Because $\\sum_{i=1}^n (X_i - \\bar{X})^2$ and $\\sum_{i=1}^n (X_ - \\bar{X})$  are functions only of the xi, they are nonrandom in the conditioning. Therefore, and keeping the conditioning on {x1, x2, ..., xn} implicit, we have\n",
    "$$\n",
    "\\mathbb{E}(\\frac{\\sum_{i=1}^n (X_i - \\bar{X})u_{i}}{\\sum_{i=1}^n (X_i - \\bar{X})^2}) = \\frac{\\sum_{i=1}^n (X_i - \\bar{X})\\mathbb{E}(u_{i})}{\\sum_{i=1}^n (X_i - \\bar{X})^2}\n",
    "$$\n",
    "\n",
    "The fundamentale hypothesis tells us that $\\mathbb{E}(u_{i}|X_{i})= 0$. Therefore,  $\\mathbb{E}(u_{i})= 0$\n",
    "\n",
    "Thus,\n",
    "$$\n",
    "\\boxed{\\mathbb{\\hat\\beta_1} = \\beta_1 \\Rightarrow  \\text{$\\hat\\beta_1$ is unbiased}}\n",
    "$$\n",
    "\n",
    "Now, let's move on to $\\hat{\\beta}_0$:\n",
    "\n",
    "To demonstrate that $\\hat{\\beta}_0$ (the estimator of $\\beta_0$) is unbiased in the context of linear regression, we will show that the expectation of $\\hat{\\beta}_0$ is equal to $\\beta_0$.\n",
    "\n",
    "The estimator for $\\beta_0$ is defined as follows:\n",
    "$$\n",
    "\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1 \\bar{X}\n",
    "$$\n",
    "\n",
    "Now, let's calculate the expectation of $\\hat{\\beta}_0$:\n",
    "$$\n",
    "E(\\hat{\\beta}_0) = E(\\bar{Y} - \\hat{\\beta}_1 \\bar{X}) = E(\\bar{Y}) - E(\\hat{\\beta}_1 \\bar{X})\n",
    "$$\n",
    "\n",
    "Since $\\bar{Y}$ and $\\bar{X}$ are constants (non-random), we can pull them out of the expectation:\n",
    "$$\n",
    "E(\\hat{\\beta}_0) = \\bar{Y} - \\bar{X}E(\\hat{\\beta}_1)\n",
    "$$\n",
    "\n",
    "Now, the estimator for $\\beta_1$ ($\\hat{\\beta}_1$) is generally considered unbiased, so $E(\\hat{\\beta}_1) = \\beta_1$. Substituting this into the expression:\n",
    "$$\n",
    "E(\\hat{\\beta}_0) = \\bar{Y} - \\bar{X}\\beta_1\n",
    "$$\n",
    "\n",
    "Let's compare this with the true value of $\\beta_0$ in the regression model:\n",
    "$$\n",
    "\\beta_0 = E(Y) - \\beta_1E(X)\n",
    "$$\n",
    "\n",
    "Knowing that $\\bar{Y} = E(Y)$ and $\\bar{X} = E(X)$, we can rewrite the expression for $\\beta_0$:\n",
    "$$\n",
    "\\beta_0 = \\bar{Y} - \\beta_1 \\bar{X}\n",
    "$$\n",
    "\n",
    "Now, let's compare $E(\\hat{\\beta}_0)$ and $\\beta_0$:\n",
    "$$\n",
    "E(\\hat{\\beta}_0) = \\bar{Y} - \\bar{X}\\beta_1 \\Rightarrow \\boxed{\\beta_0 = \\bar{Y} - \\beta_1 \\bar{X}}\n",
    "$$\n",
    "\n",
    "As we can see, $E(\\hat{\\beta}_0) = \\beta_0$, indicating that $\\hat{\\beta}_0$ is unbiased.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
